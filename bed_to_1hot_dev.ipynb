{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyfaidx import Fasta\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEDCOLS = [\n",
    "    \"chrom\",\n",
    "    \"chromStart\",\n",
    "    \"chromEnd\",\n",
    "    \"name\",\n",
    "    \"score\",\n",
    "    \"strand\",\n",
    "    \"thickStart\",\n",
    "    \"thickEnd\",\n",
    "    \"itemRGB\",\n",
    "    \"blockCount\",\n",
    "    \"blockSizes\",\n",
    "    \"blockStarts\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_colnames(df, labelnum=0):  # need to be adjusted for GC content\n",
    "    \"\"\"Generates column names for an input dataframe.\n",
    "\n",
    "    Arguments:\n",
    "        df [dataframe] -- [dataframe for which column names are generated]\n",
    "\n",
    "    Returns:\n",
    "        [list] -- [list of generated column names]\n",
    "    \"\"\"\n",
    "    colnames = []\n",
    "    for field in range(len(df.columns) - labelnum):\n",
    "        colnames.append(BEDCOLS[field])\n",
    "    for label in range(labelnum):\n",
    "        colnames.append(f\"label_{label+1}\")\n",
    "    return colnames\n",
    "\n",
    "\n",
    "def read_bed_file(path, labelnum=0):\n",
    "    \"\"\"reads .bed file into pandas dataframe\n",
    "\n",
    "    Args:\n",
    "        path (str): path to bed file\n",
    "\n",
    "    Returns:\n",
    "        [pandas dataframe]: dataframe containing all fields contained in bed file\n",
    "    \"\"\"\n",
    "\n",
    "    bed_df = pd.read_table(path, sep=\"\\t\", header=None)\n",
    "    colnames = generate_colnames(bed_df, labelnum)\n",
    "    bed_df.columns = colnames\n",
    "    print(bed_df.head())\n",
    "    return bed_df\n",
    "\n",
    "\n",
    "def one_hot_encoding(sequence):\n",
    "    \"\"\"One hot encoding of a DNA sequence.\n",
    "\n",
    "    Args:\n",
    "        sequence (str): [DNA sequence in IUPAC format]\n",
    "\n",
    "    Returns:\n",
    "        [numpy array]: [one hot encoded DNA sequence]\n",
    "    \"\"\"\n",
    "\n",
    "    mydict = {\n",
    "        \"A\": np.asarray([1, 0, 0, 0]),\n",
    "        \"a\": np.asarray([1, 0, 0, 0]),\n",
    "        \"C\": np.asarray([0, 1, 0, 0]),\n",
    "        \"c\": np.asarray([0, 1, 0, 0]),\n",
    "        \"G\": np.asarray([0, 0, 1, 0]),\n",
    "        \"g\": np.asarray([0, 0, 1, 0]),\n",
    "        \"T\": np.asarray([0, 0, 0, 1]),\n",
    "        \"t\": np.asarray([0, 0, 0, 1]),\n",
    "        \"Y\": np.asarray([0, 1, 0, 1]),\n",
    "        \"y\": np.asarray([0, 1, 0, 1]),\n",
    "        \"R\": np.asarray([1, 0, 1, 0]),\n",
    "        \"r\": np.asarray([1, 0, 1, 0]),\n",
    "        \"S\": np.asarray([0, 1, 1, 0]),\n",
    "        \"s\": np.asarray([0, 1, 1, 0]),\n",
    "        \"W\": np.asarray([1, 0, 0, 1]),\n",
    "        \"w\": np.asarray([1, 0, 0, 1]),\n",
    "        \"K\": np.asarray([0, 0, 1, 1]),\n",
    "        \"k\": np.asarray([0, 0, 1, 1]),\n",
    "        \"M\": np.asarray([1, 1, 0, 0]),\n",
    "        \"m\": np.asarray([1, 1, 0, 0]),\n",
    "        \"B\": np.asarray([0, 1, 1, 1]),\n",
    "        \"b\": np.asarray([0, 1, 1, 1]),\n",
    "        \"D\": np.asarray([1, 0, 1, 1]),\n",
    "        \"d\": np.asarray([1, 0, 1, 1]),\n",
    "        \"H\": np.asarray([1, 1, 0, 1]),\n",
    "        \"h\": np.asarray([1, 1, 0, 1]),\n",
    "        \"V\": np.asarray([1, 1, 1, 0]),\n",
    "        \"v\": np.asarray([1, 1, 1, 0]),\n",
    "        \"N\": np.asarray([0, 0, 0, 0]),\n",
    "        \"n\": np.asarray([0, 0, 0, 0]),\n",
    "        \"-\": np.asarray([0, 0, 0, 0]),\n",
    "    }\n",
    "    print(f\"Seq: {sequence}\")\n",
    "    if len(sequence) > 0:\n",
    "        nuc_list = list()\n",
    "        for nuc in list(sequence):\n",
    "            nuc_list.append(mydict[nuc])\n",
    "        result = np.stack(np.asarray(nuc_list, dtype=\"int8\"))\n",
    "        return result\n",
    "    else: \n",
    "        print(\"ERROR! sequence is too short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bed_encoding(bed_df, reference):\n",
    "    \"\"\"One Hot encoding of regions in a bed file.\n",
    "\n",
    "    Args:\n",
    "        bed_df (pandas Dataframe): [Dataframe of bed file]\n",
    "        reference (fasta file): [Genome reference file in fasta format]\n",
    "\n",
    "    Returns:\n",
    "        [numpy array]: [One hot encoded DNA sequences from bed file]\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = Fasta(reference, as_raw=True)\n",
    "    seq_list = list()\n",
    "    for _, i in bed_df.iterrows():\n",
    "        print(f\"region:{i[0]}:{i[1]}-{i[2]}\")\n",
    "        seq_list.append(one_hot_encoding(fasta[i[0]][i[1]:i[2]]))\n",
    "    result = np.stack(seq_list)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(bed_df, v_holdout, t_holdout, ref):\n",
    "    x_train = y_train = x_val = y_val = x_test = y_test = None\n",
    "    \n",
    "    if t_holdout is not None and v_holdout is not None:\n",
    "        train_df = bed_df.loc[~bed_df[\"chrom\"].isin(t_holdout + v_holdout)]\n",
    "        validate_df = bed_df.loc[bed_df[\"chrom\"].isin(v_holdout)]\n",
    "        test_df = bed_df.loc[bed_df[\"chrom\"].isin(t_holdout)]\n",
    "        x_train = bed_encoding(train_df, ref)\n",
    "        y_train = np.asarray(\n",
    "            train_df.loc[:, train_df.columns.str.contains(\"label\")], dtype=\"int8\"\n",
    "        )  # .flatten()\n",
    "        x_val = bed_encoding(validate_df, ref)\n",
    "        y_val = np.asarray(\n",
    "            validate_df.loc[:, validate_df.columns.str.contains(\"label\")], dtype=\"int8\"\n",
    "        )  # .flatten()\n",
    "        x_test = bed_encoding(test_df, ref)\n",
    "        y_test = np.asarray(\n",
    "            test_df.loc[:, test_df.columns.str.contains(\"label\")], dtype=\"int8\"\n",
    "        ) \n",
    "        \n",
    "    elif t_holdout is not None:\n",
    "        train_df = bed_df.loc[~bed_df[\"chrom\"].isin(t_holdout)]\n",
    "        test_df = bed_df.loc[bed_df[\"chrom\"].isin(t_holdout)]\n",
    "        x_train = bed_encoding(train_df, ref)\n",
    "        y_train = np.asarray(\n",
    "            train_df.loc[:, train_df.columns.str.contains(\"label\")], dtype=\"int8\"\n",
    "        )  # .flatten()\n",
    "        x_test = bed_encoding(test_df, ref)\n",
    "        y_test = np.asarray(\n",
    "            test_df.loc[:, test_df.columns.str.contains(\"label\")], dtype=\"int8\"\n",
    "        )  # .flatten()\n",
    "    elif v_holdout is not None:\n",
    "        train_df = bed_df.loc[~bed_df[\"chrom\"].isin(v_holdout)]\n",
    "        validate_df = bed_df.loc[bed_df[\"chrom\"].isin(v_holdout)]\n",
    "        x_train = bed_encoding(train_df, ref)\n",
    "        y_train = np.asarray(\n",
    "            train_df.loc[:, train_df.columns.str.contains(\"label\")], dtype=\"int8\"\n",
    "        )  # .flatten()\n",
    "        x_val = bed_encoding(validate_df, ref)\n",
    "        y_val = np.asarray(\n",
    "            validate_df.loc[:, validate_df.columns.str.contains(\"label\")], dtype=\"int8\"\n",
    "        )  # .flatten()\n",
    "    else:\n",
    "        train_df = bed_df\n",
    "        x_train = bed_encoding(train_df, ref)\n",
    "        y_train = np.asarray(\n",
    "            train_df.loc[:, train_df.columns.str.contains(\"label\")], dtype=\"int8\"\n",
    "        )  # .flatten()\n",
    "    \n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_hd5(out_file, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    \"\"\"Writes train,validate,test arrays to HD5 format\"\"\"\n",
    "    data = h5py.File(out_file, \"w\")\n",
    "    train_data = data.create_group(\"train_data\")\n",
    "    train_data.create_dataset(\"x_train\", data=x_train)\n",
    "    train_data.create_dataset(\"y_train\", data=y_train)\n",
    "    if x_val is not None:\n",
    "        val_data = data.create_group(\"val_data\")\n",
    "        val_data.create_dataset(\"x_val\", data=x_val)\n",
    "        val_data.create_dataset(\"y_val\", data=y_val)\n",
    "    if x_test is not None:\n",
    "        test_data = data.create_group(\"test_data\")\n",
    "        test_data.create_dataset(\"x_test\", data=x_test)\n",
    "        test_data.create_dataset(\"y_test\", data=y_test)\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bed_to_1hot(input_file, output_file, reference, label_num, v_holdout, t_holdout):\n",
    "    \"\"\"Takes a bedfile, queries a fasta file and saves the one hot encoded sequences to hd5.\"\"\"\n",
    "    bed_df = read_bed_file(input_file, label_num)\n",
    "    # print(\"generating data split\")\n",
    "    print(bed_df.head())\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = train_validate_test_split(\n",
    "        bed_df=bed_df, ref=reference, v_holdout=v_holdout, t_holdout=t_holdout\n",
    "    )\n",
    "    save_to_hd5(\n",
    "        out_file=output_file,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_val=x_val,\n",
    "        y_val=y_val,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=\"tests/test_data/encoding_test_2label.bed\"\n",
    "output_file=\"test.h5\"\n",
    "reference=\"/home/user/git_private/data/reference/hs38.fa\"\n",
    "label_num=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_holdout=None\n",
    "v_holdout=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_holdout=[\"chr1\"]\n",
    "v_holdout=[\"chr2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_holdout=None\n",
    "v_holdout=[\"chr2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_holdout=[\"chr1\"]\n",
    "v_holdout=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chrom  chromStart   chromEnd  name  score strand  label_1  label_2\n",
      "0  chr18    17431849   17431859     1     10      -        0        1\n",
      "1   chr5    21210294   21210304     2     10      +        1        0\n",
      "2   chr6    94689432   94689442     3     10      +        0        1\n",
      "3   chr2   215518670  215518680     4     10      -        1        0\n",
      "4   chr9    93351305   93351315     5     10      +        0        1\n",
      "   chrom  chromStart   chromEnd  name  score strand  label_1  label_2\n",
      "0  chr18    17431849   17431859     1     10      -        0        1\n",
      "1   chr5    21210294   21210304     2     10      +        1        0\n",
      "2   chr6    94689432   94689442     3     10      +        0        1\n",
      "3   chr2   215518670  215518680     4     10      -        1        0\n",
      "4   chr9    93351305   93351315     5     10      +        0        1\n",
      "region:chr18:17431849-17431859\n",
      "Seq: AGAGTTGAAC\n",
      "region:chr5:21210294-21210304\n",
      "Seq: ATTGTGCCAT\n",
      "region:chr6:94689432-94689442\n",
      "Seq: CCAAGCAGAA\n",
      "region:chr2:215518670-215518680\n",
      "Seq: AAAGGTGAAC\n",
      "region:chr9:93351305-93351315\n",
      "Seq: CTATGCTCAA\n",
      "region:chr15:99131808-99131818\n",
      "Seq: TGGAGGTAAG\n",
      "region:chr9:84629995-84630005\n",
      "Seq: GAGTTAGCAG\n",
      "region:chr21:18348734-18348744\n",
      "Seq: TTGAGCAGAG\n",
      "region:chr4:37878592-37878602\n",
      "Seq: CATGGTGAAA\n",
      "region:chr1:70548969-70548979\n",
      "Seq: GTGGAATAAG\n"
     ]
    }
   ],
   "source": [
    "bed_to_1hot(input_file=input_file, output_file=output_file, reference=reference, label_num=label_num, v_holdout=v_holdout, t_holdout=t_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=h5py.File(\"test.h5\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['test_data', 'train_data']>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['x_train', 'y_train']>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[\"train_data\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"x_train\": shape (9, 10, 4), type \"|i1\">"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[\"train_data\"][\"x_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'val_data' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-b7883fa46c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.8/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'val_data' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "dt[\"val_data\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'val_data' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-7216ce8219c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x_val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.8/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'val_data' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "dt[\"val_data\"][\"x_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['x_test', 'y_test']>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[\"test_data\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"x_test\": shape (1, 10, 4), type \"|i1\">"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[\"test_data\"][\"x_test\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
